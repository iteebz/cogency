import asyncio
import time
from unittest.mock import Mock

from cogency.reasoning.loop_integration import ReasoningLoopGuard, with_loop_detection
from cogency.reasoning.loop_detection import LoopDetectionConfig, LoopType
from cogency.common.types import ExecutionTrace
from cogency.context import Context


class TestReasoningLoopGuard:
    """Test suite for reasoning loop guard."""
    
    def test_reasoning_session_lifecycle(self):
        """Test complete reasoning session lifecycle."""
        guard = ReasoningLoopGuard()
        
        # Start session
        session_info = guard.start_reasoning_session("Test query", [])
        
        assert "session_id" in session_info
        assert "complexity_factor" in session_info
        assert guard.session_active == True
        
        # End session
        summary = guard.end_reasoning_session()
        
        assert "session_ended_at" in summary
        assert guard.session_active == False
        print("âœ… Reasoning session lifecycle")
    
    def test_reasoning_step_safety_check(self):
        """Test reasoning step safety checking."""
        guard = ReasoningLoopGuard()
        guard.start_reasoning_session("Test query", [])
        
        # Create mock state
        context = Context("test query")
        trace = ExecutionTrace()
        trace.add("memorize", "Processing")
        
        state = {
            "context": context,
            "trace": trace,
            "selected_tools": []
        }
        
        # Safe reasoning step
        result = guard.check_reasoning_step(
            state=state,
            iteration=1,
            llm_response="I need to analyze this",
            tool_calls=[],
            execution_results={}
        )
        
        assert result["safe"] == True
        assert len(result["loops"]) == 0
        assert result["should_stop"] == False
        print("âœ… Reasoning step safety check")
    
    def test_tool_execution_monitoring(self):
        """Test tool execution loop monitoring."""
        guard = ReasoningLoopGuard()
        guard.start_reasoning_session("Test query", [])
        
        # Safe tool execution
        result = guard.check_tool_execution(
            tool_name="search",
            args={"query": "test"},
            result="search result",
            success=True
        )
        
        assert result["safe"] == True
        assert len(result["loops"]) == 0
        assert result["tool_retry_count"] == 1
        print("âœ… Tool execution monitoring")
    
    def test_decision_pattern_detection(self):
        """Test decision pattern detection."""
        guard = ReasoningLoopGuard()
        guard.start_reasoning_session("Test query", [])
        
        # Safe decision
        result = guard.check_decision_pattern(
            decision_type="use_tools",
            details={"tools": ["search"]}
        )
        
        assert result["safe"] == True
        assert len(result["loops"]) == 0
        print("âœ… Decision pattern detection")
    
    def test_emergency_stop_recommendation(self):
        """Test emergency stop recommendation."""
        guard = ReasoningLoopGuard()
        guard.start_reasoning_session("Test query", [])
        
        # No loops initially
        recommendation = guard.get_emergency_stop_recommendation()
        assert recommendation["recommend_stop"] == False
        
        # Simulate many tool executions to trigger emergency stop
        for i in range(10):
            guard.check_tool_execution(
                tool_name="search",
                args={"query": f"test_{i}"},
                result=None,
                success=False
            )
        
        # Should recommend stop due to too many failures
        recommendation = guard.get_emergency_stop_recommendation()
        # Note: May or may not trigger depending on loop detection thresholds
        assert "recommend_stop" in recommendation
        print("âœ… Emergency stop recommendation")
    
    def test_complexity_estimation(self):
        """Test query complexity estimation."""
        guard = ReasoningLoopGuard()
        
        # Simple query
        simple_complexity = guard._estimate_complexity("What is Python?", [])
        
        # Complex query
        complex_complexity = guard._estimate_complexity(
            "Analyze and compare the comprehensive performance implications of different machine learning frameworks",
            ["tool1", "tool2", "tool3"]
        )
        
        assert simple_complexity < complex_complexity
        assert 0.1 <= simple_complexity <= 1.0
        assert 0.1 <= complex_complexity <= 1.0
        print("âœ… Complexity estimation")
    
    def test_loop_warning_to_trace(self):
        """Test loop warning addition to trace."""
        guard = ReasoningLoopGuard()
        guard.start_reasoning_session("Test query", [])
        
        # Create mock trace
        trace = ExecutionTrace()
        trace.add("memorize", "Processing")
        
        # Create mock loops
        from cogency.utils.loop_detection import LoopPattern
        mock_loop = LoopPattern(
            loop_type=LoopType.REASONING_CYCLE,
            cycle_length=2,
            repetition_count=3,
            first_occurrence=time.time(),
            last_occurrence=time.time(),
            confidence=0.9,
            signature="test_sig"
        )
        
        # Add warning
        guard._add_loop_warning_to_trace(trace, [mock_loop])
        
        # Check trace has warning
        loop_entries = [e for e in trace.entries if e["node"] == "loop_guard"]
        assert len(loop_entries) == 1
        assert "Loop detected" in loop_entries[0]["message"]
        print("âœ… Loop warning to trace")
    
    def test_inactive_session_safety(self):
        """Test safety when session is inactive."""
        guard = ReasoningLoopGuard()
        
        # Should be safe when session not active
        result = guard.check_reasoning_step(
            state={},
            iteration=1,
            llm_response="test",
            tool_calls=[],
            execution_results={}
        )
        
        assert result["safe"] == True
        assert len(result["loops"]) == 0
        print("âœ… Inactive session safety")


class TestLoopDetectionDecorator:
    """Test suite for loop detection decorator."""
    
    async def test_decorator_basic_functionality(self):
        """Test basic decorator functionality."""
        
        @with_loop_detection()
        async def mock_reasoning_function(state):
            # Simulate reasoning work
            await asyncio.sleep(0.1)
            return {
                "context": state["context"],
                "trace": state["trace"],
                "reasoning_decision": {"should_respond": True}
            }
        
        # Create mock state
        context = Context("test query")
        trace = ExecutionTrace()
        state = {
            "context": context,
            "trace": trace,
            "selected_tools": []
        }
        
        # Test decorator
        result = await mock_reasoning_function(state)
        
        assert "context" in result
        assert "trace" in result
        assert "reasoning_decision" in result
        print("âœ… Decorator basic functionality")
    
    async def test_decorator_with_invalid_state(self):
        """Test decorator with invalid state."""
        
        @with_loop_detection()
        async def mock_function_invalid_state(invalid_state):
            return {"result": "test"}
        
        # Should work without crashing
        result = await mock_function_invalid_state("not a dict")
        assert result["result"] == "test"
        print("âœ… Decorator with invalid state")


async def test_loop_integration_full_suite():
    """Test complete loop integration suite."""
    print("ðŸ›¡ï¸  Testing loop integration system...")
    
    # Test guard
    guard_tests = TestReasoningLoopGuard()
    guard_tests.test_reasoning_session_lifecycle()
    guard_tests.test_reasoning_step_safety_check()
    guard_tests.test_tool_execution_monitoring()
    guard_tests.test_decision_pattern_detection()
    guard_tests.test_emergency_stop_recommendation()
    guard_tests.test_complexity_estimation()
    guard_tests.test_loop_warning_to_trace()
    guard_tests.test_inactive_session_safety()
    
    # Test decorator
    decorator_tests = TestLoopDetectionDecorator()
    await decorator_tests.test_decorator_basic_functionality()
    await decorator_tests.test_decorator_with_invalid_state()
    
    print("\nðŸŽ‰ All loop integration tests passed!")
